{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "NZEF_F2EKEr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "552f02bc-e875-4fd1-eb30-7bbbf694ea9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas_ta\n",
            "  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pandas_ta) (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.16.0)\n",
            "Building wheels for collected packages: pandas_ta\n",
            "  Building wheel for pandas_ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas_ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218907 sha256=0d252fc1871dc432f0ed2c49ed737c247cc55370b71f8330c09cb4db794ba23e\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/00/ac/f7fa862c34b0e2ef320175100c233377b4c558944f12474cf0\n",
            "Successfully built pandas_ta\n",
            "Installing collected packages: pandas_ta\n",
            "Successfully installed pandas_ta-0.3.14b0\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from datetime import date, timedelta\n",
        "import pprint\n",
        "import pandas as pd\n",
        "from time import sleep\n",
        "import yfinance as yf\n",
        "!pip install pandas_ta\n",
        "import pandas_ta as ta\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goJI7IS_mEfm"
      },
      "source": [
        "**Download News Sentiment Meethod**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ldp4XuvlKHeW"
      },
      "outputs": [],
      "source": [
        "def pull_news(cur_date,ticker,limit=100):\n",
        "  api_key = \"DJ6ADDN7HUrgAXHVwxQ0vBUrtpIykzXy\"\n",
        "  news = []\n",
        "  url = f\"https://api.polygon.io/v2/reference/news?ticker={ticker}&limit=100&published_utc={cur_date}&apiKey={api_key}\"\n",
        "  response = requests.get(url)\n",
        "\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    # pprint.pprint(data)\n",
        "    results = data.get(\"results\", [])\n",
        "    # pprint.pprint(results)\n",
        "\n",
        "    for article in results:\n",
        "      news.append(article)\n",
        "\n",
        "\n",
        "    else: print(response.status_code)\n",
        "    # sleep(60)\n",
        "\n",
        "  return news\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "78kZKh5MqjxF"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "start_date = datetime.strptime(\"2024-04-03\", \"%Y-%m-%d\")\n",
        "end_date = datetime.strptime(\"2024-04-04\", \"%Y-%m-%d\")\n",
        "\n",
        "date_range = []\n",
        "current_date = start_date\n",
        "\n",
        "while current_date <= end_date:\n",
        "    date_range.append(current_date.strftime(\"%Y-%m-%d\"))\n",
        "    current_date += timedelta(days=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2DdH3OxrHFQ"
      },
      "outputs": [],
      "source": [
        "from time import sleep\n",
        "aapl_news = []\n",
        "spy_news  = []\n",
        "for date in date_range:\n",
        "  aapl_news.append(pull_news(date,\"AAPL\"))\n",
        "  spy_news.append(pull_news(date,\"SPY\"))\n",
        "  # sleep(60/5*2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')\n",
        "model = BertForSequenceClassification.from_pretrained('ProsusAI/finbert')\n",
        "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "61fCFy1t8JAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = {}\n",
        "\n",
        "for day in aapl_news:\n",
        "    for article in day:\n",
        "        cur_date = article.get(\"published_utc\")[:10]\n",
        "        cur_description = article.get(\"description\")\n",
        "        value = nlp(cur_description)\n",
        "        print(value)\n",
        "        sentiment.setdefault(cur_date, {\"neg\": 0, \"pos\": 0})\n",
        "        val = value[0].get(\"label\")\n",
        "        score = float(value[0].get(\"score\"))\n",
        "        print(score)\n",
        "        if val == \"negative\":\n",
        "            sentiment[cur_date][\"neg\"] += score\n",
        "        elif val == \"positive\":\n",
        "            sentiment[cur_date][\"pos\"] += score\n"
      ],
      "metadata": {
        "id": "3nnC88HgVOoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentiment)\n",
        "aapl = yf.download(\"AAPL\",start=start_date,end=end_date+timedelta(1),progress=False).reset_index()\n",
        "aapl[\"pos\"], aapl[\"neg\"] = [0]*len(aapl), [0]*len(aapl)\n",
        "print(aapl)"
      ],
      "metadata": {
        "id": "Ix1WN-PE6mPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(aapl)):\n",
        "  cur_date = str(datetime.strftime(aapl[\"Date\"][i],\"%Y-%m-%d\"))\n",
        "  if cur_date in sentiment:\n",
        "    aapl[\"pos\"][i] = sentiment[cur_date][\"pos\"]\n",
        "    aapl[\"neg\"][i] = sentiment[cur_date][\"neg\"]\n"
      ],
      "metadata": {
        "id": "UUiKw4uNBupa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(aapl)"
      ],
      "metadata": {
        "id": "VEcFkkKJB0pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "aapl = pd.read_csv(\"/content/raw_news_2.csv\")\n",
        "aapl = aapl[(aapl[\"Ticker\"] == \"AAPL\") & (aapl[\"Positive\"] + aapl[\"Negative\"] > 0)].reset_index(drop=True)\n",
        "aapl[\"ROC\"] = aapl[\"Close\"].shift(-1)/aapl[\"Close\"]-1\n",
        "# Assuming you've already loaded your data into the 'aapl' DataFrame\n",
        "# Print the modified DataFrame\n",
        "print(aapl)\n",
        "aapl = aapl.dropna()\n",
        "# Print the filtered DataFrame\n",
        "print(aapl)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j185WInuDYxY",
        "outputId": "29f443ab-1031-43cc-9843-087174bae995"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Date Ticker        Open        High         Low       Close  \\\n",
            "0    12/30/2021   AAPL  179.470001  180.570007  178.089996  178.199997   \n",
            "1    12/31/2021   AAPL  178.089996  179.229996  177.259995  177.570007   \n",
            "2      1/3/2022   AAPL  177.830002  182.880005  177.710007  182.009995   \n",
            "3      1/4/2022   AAPL  182.630005  182.940002  179.119995  179.699997   \n",
            "4      1/5/2022   AAPL  179.610001  180.169998  174.639999  174.919998   \n",
            "..          ...    ...         ...         ...         ...         ...   \n",
            "303   5/23/2023   AAPL  173.130005  173.380005  171.279999  171.559998   \n",
            "304   5/24/2023   AAPL  171.089996  172.419998  170.520004  171.839996   \n",
            "305   5/25/2023   AAPL  172.410004  173.899994  171.690002  172.990005   \n",
            "306   5/30/2023   AAPL  176.960007  178.990005  176.570007  177.300003   \n",
            "307   5/31/2023   AAPL  177.330002  179.350006  176.759995  177.250000   \n",
            "\n",
            "      Adj Close     Volume      Sector  Positive  Negative   Neutral       ROC  \n",
            "0    176.186935   59773000  Technology  1.000000  0.996691  4.999918 -0.003535  \n",
            "1    175.564056   64062300  Technology  3.707866  0.000000  0.999704  0.025004  \n",
            "2    179.953888  104487900  Technology  5.523852  0.851335  4.981308 -0.012692  \n",
            "3    177.669983   99310400  Technology  4.423356  1.992809  4.998459 -0.026600  \n",
            "4    172.943970   94537600  Technology  1.978258  0.000000  5.455402 -0.016693  \n",
            "..          ...        ...         ...       ...       ...       ...       ...  \n",
            "303  171.103226   50747300  Technology  0.999993  0.000000  0.982607  0.001632  \n",
            "304  171.382477   45143500  Technology  1.981000  0.997013  2.999920  0.006692  \n",
            "305  172.529419   56058300  Technology  0.000000  0.999999  0.999997  0.024915  \n",
            "306  176.827942   55964400  Technology  0.999989  0.000000  4.706739 -0.000282  \n",
            "307  176.778061   99625300  Technology  1.999993  0.999989  0.999581       NaN  \n",
            "\n",
            "[308 rows x 13 columns]\n",
            "           Date Ticker        Open        High         Low       Close  \\\n",
            "0    12/30/2021   AAPL  179.470001  180.570007  178.089996  178.199997   \n",
            "1    12/31/2021   AAPL  178.089996  179.229996  177.259995  177.570007   \n",
            "2      1/3/2022   AAPL  177.830002  182.880005  177.710007  182.009995   \n",
            "3      1/4/2022   AAPL  182.630005  182.940002  179.119995  179.699997   \n",
            "4      1/5/2022   AAPL  179.610001  180.169998  174.639999  174.919998   \n",
            "..          ...    ...         ...         ...         ...         ...   \n",
            "302   5/22/2023   AAPL  173.979996  174.710007  173.449997  174.199997   \n",
            "303   5/23/2023   AAPL  173.130005  173.380005  171.279999  171.559998   \n",
            "304   5/24/2023   AAPL  171.089996  172.419998  170.520004  171.839996   \n",
            "305   5/25/2023   AAPL  172.410004  173.899994  171.690002  172.990005   \n",
            "306   5/30/2023   AAPL  176.960007  178.990005  176.570007  177.300003   \n",
            "\n",
            "      Adj Close     Volume      Sector  Positive  Negative   Neutral       ROC  \n",
            "0    176.186935   59773000  Technology  1.000000  0.996691  4.999918 -0.003535  \n",
            "1    175.564056   64062300  Technology  3.707866  0.000000  0.999704  0.025004  \n",
            "2    179.953888  104487900  Technology  5.523852  0.851335  4.981308 -0.012692  \n",
            "3    177.669983   99310400  Technology  4.423356  1.992809  4.998459 -0.026600  \n",
            "4    172.943970   94537600  Technology  1.978258  0.000000  5.455402 -0.016693  \n",
            "..          ...        ...         ...       ...       ...       ...       ...  \n",
            "302  173.736191   43570900  Technology  1.999934  1.999889  2.995879 -0.015155  \n",
            "303  171.103226   50747300  Technology  0.999993  0.000000  0.982607  0.001632  \n",
            "304  171.382477   45143500  Technology  1.981000  0.997013  2.999920  0.006692  \n",
            "305  172.529419   56058300  Technology  0.000000  0.999999  0.999997  0.024915  \n",
            "306  176.827942   55964400  Technology  0.999989  0.000000  4.706739 -0.000282  \n",
            "\n",
            "[307 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Assuming you've already loaded your data into 'aapl'\n",
        "X = aapl[[\"Positive\", \"Negative\"]]\n",
        "Y = aapl[\"ROC\"]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost model\n",
        "model = xgb.XGBRegressor(objective=\"reg:squarederror\")  # For regression tasks\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "print(f\"Mean Squared Error: {mse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pARS-besVmwg",
        "outputId": "e23f0e39-6372-4655-8f60-08c648fa4ef0"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.0009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_pred)\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8CGOsJJV1K5",
        "outputId": "f9663c8d-ffce-40d4-a4db-26a7d6f017f4"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.0146271   0.01788503  0.00260168 -0.01263983  0.00138683 -0.00389833\n",
            "  0.01942861 -0.01871114  0.00340011 -0.00491163 -0.00823705 -0.00141775\n",
            " -0.00951122  0.00014855  0.00029288 -0.0090176   0.01799224 -0.0146271\n",
            " -0.00916618 -0.0325922   0.00119991  0.001716   -0.00389833 -0.00646324\n",
            "  0.01412083  0.02257626  0.04325802 -0.00227291 -0.01988783 -0.00706911\n",
            "  0.00092463 -0.03318041  0.01387393  0.0204523  -0.02116739 -0.03085133\n",
            " -0.00389833  0.03694133  0.00097057 -0.00314714  0.0244362  -0.00491163\n",
            "  0.01585262 -0.02356122  0.01093447  0.0037513  -0.00389833 -0.01681654\n",
            " -0.00501787 -0.00344847 -0.00501787 -0.00577591 -0.04082998 -0.02475606\n",
            " -0.00048616 -0.039113   -0.00389833 -0.01123446  0.03212057 -0.00229407\n",
            "  0.01018432  0.01826942]\n",
            "0     -0.003535\n",
            "1      0.025004\n",
            "2     -0.012692\n",
            "3     -0.026600\n",
            "4     -0.016693\n",
            "         ...   \n",
            "302   -0.015155\n",
            "303    0.001632\n",
            "304    0.006692\n",
            "305    0.024915\n",
            "306   -0.000282\n",
            "Name: ROC, Length: 307, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aapl['ROC'] = aapl['ROC'].apply(lambda x: 0 if x < 0 else 1)"
      ],
      "metadata": {
        "id": "PLOfZOcsVe_6"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you've already loaded your data into 'aapl'\n",
        "X = aapl[[\"Positive\", \"Negative\"]]\n",
        "Y = aapl[\"ROC\"]  # Assuming ROC is already modified to be binary (0 or 1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost model\n",
        "model = xgb.XGBClassifier(objective=\"binary:logistic\")  # For binary classification\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "precision = precision_score(Y_test, Y_pred)\n",
        "recall = recall_score(Y_test, Y_pred)\n",
        "f1 = f1_score(Y_test, Y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZcaza50E5rV",
        "outputId": "e326f1c5-b2eb-49e6-a0bb-1eca68f5cb61"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normalize features (sentiment scores)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(2,)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Sigmoid activation for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, epochs=100, validation_data=(X_test, Y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(f\"Accuracy on test data: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV8RF6o-MWA0",
        "outputId": "948d1681-47ae-4d91-8619-2eb2b5fd8a6d"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 32ms/step - loss: 0.6997 - accuracy: 0.4531 - val_loss: 0.6953 - val_accuracy: 0.5161\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6914 - accuracy: 0.5143 - val_loss: 0.7087 - val_accuracy: 0.4194\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6895 - accuracy: 0.5184 - val_loss: 0.7230 - val_accuracy: 0.4194\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6782 - accuracy: 0.5592 - val_loss: 0.7315 - val_accuracy: 0.4194\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6776 - accuracy: 0.5510 - val_loss: 0.7386 - val_accuracy: 0.4194\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6768 - accuracy: 0.5510 - val_loss: 0.7441 - val_accuracy: 0.4194\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6818 - accuracy: 0.5469 - val_loss: 0.7479 - val_accuracy: 0.4194\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6752 - accuracy: 0.5551 - val_loss: 0.7534 - val_accuracy: 0.4194\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6780 - accuracy: 0.5469 - val_loss: 0.7577 - val_accuracy: 0.4194\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6738 - accuracy: 0.5469 - val_loss: 0.7626 - val_accuracy: 0.4194\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6779 - accuracy: 0.5510 - val_loss: 0.7610 - val_accuracy: 0.4194\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6742 - accuracy: 0.5592 - val_loss: 0.7628 - val_accuracy: 0.4194\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6740 - accuracy: 0.5551 - val_loss: 0.7663 - val_accuracy: 0.4194\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6767 - accuracy: 0.5469 - val_loss: 0.7732 - val_accuracy: 0.4194\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6752 - accuracy: 0.5510 - val_loss: 0.7692 - val_accuracy: 0.4677\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6748 - accuracy: 0.5510 - val_loss: 0.7701 - val_accuracy: 0.4677\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6748 - accuracy: 0.5551 - val_loss: 0.7701 - val_accuracy: 0.4677\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6730 - accuracy: 0.5388 - val_loss: 0.7698 - val_accuracy: 0.4839\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.6745 - accuracy: 0.5306 - val_loss: 0.7717 - val_accuracy: 0.4677\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6718 - accuracy: 0.5592 - val_loss: 0.7754 - val_accuracy: 0.4677\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6741 - accuracy: 0.5592 - val_loss: 0.7762 - val_accuracy: 0.4516\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6722 - accuracy: 0.5551 - val_loss: 0.7768 - val_accuracy: 0.4516\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6720 - accuracy: 0.5592 - val_loss: 0.7770 - val_accuracy: 0.4516\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6746 - accuracy: 0.5592 - val_loss: 0.7771 - val_accuracy: 0.4516\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6713 - accuracy: 0.5673 - val_loss: 0.7801 - val_accuracy: 0.4677\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6688 - accuracy: 0.5714 - val_loss: 0.7803 - val_accuracy: 0.4516\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6687 - accuracy: 0.5673 - val_loss: 0.7799 - val_accuracy: 0.4516\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6703 - accuracy: 0.5633 - val_loss: 0.7835 - val_accuracy: 0.4516\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6754 - accuracy: 0.5469 - val_loss: 0.7819 - val_accuracy: 0.4516\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6689 - accuracy: 0.5837 - val_loss: 0.7843 - val_accuracy: 0.4516\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6728 - accuracy: 0.5755 - val_loss: 0.7857 - val_accuracy: 0.4516\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6707 - accuracy: 0.5755 - val_loss: 0.7831 - val_accuracy: 0.4516\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6737 - accuracy: 0.5878 - val_loss: 0.7815 - val_accuracy: 0.4516\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6753 - accuracy: 0.5469 - val_loss: 0.7804 - val_accuracy: 0.4516\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6692 - accuracy: 0.5918 - val_loss: 0.7797 - val_accuracy: 0.4516\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6730 - accuracy: 0.5714 - val_loss: 0.7796 - val_accuracy: 0.4516\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6683 - accuracy: 0.5796 - val_loss: 0.7806 - val_accuracy: 0.4516\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6723 - accuracy: 0.5796 - val_loss: 0.7821 - val_accuracy: 0.4516\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6725 - accuracy: 0.5673 - val_loss: 0.7834 - val_accuracy: 0.4516\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6731 - accuracy: 0.5510 - val_loss: 0.7830 - val_accuracy: 0.4516\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6648 - accuracy: 0.5633 - val_loss: 0.7822 - val_accuracy: 0.4516\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6742 - accuracy: 0.5918 - val_loss: 0.7869 - val_accuracy: 0.4516\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6704 - accuracy: 0.5714 - val_loss: 0.7875 - val_accuracy: 0.4516\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6627 - accuracy: 0.5673 - val_loss: 0.7851 - val_accuracy: 0.4516\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6656 - accuracy: 0.6122 - val_loss: 0.7852 - val_accuracy: 0.4516\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6680 - accuracy: 0.5714 - val_loss: 0.7845 - val_accuracy: 0.4516\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6653 - accuracy: 0.5673 - val_loss: 0.7857 - val_accuracy: 0.4516\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6709 - accuracy: 0.5959 - val_loss: 0.7869 - val_accuracy: 0.4516\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6671 - accuracy: 0.5878 - val_loss: 0.7874 - val_accuracy: 0.4516\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6616 - accuracy: 0.6122 - val_loss: 0.7923 - val_accuracy: 0.4516\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6663 - accuracy: 0.5878 - val_loss: 0.7955 - val_accuracy: 0.4516\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6689 - accuracy: 0.5796 - val_loss: 0.7928 - val_accuracy: 0.4516\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6706 - accuracy: 0.6082 - val_loss: 0.7975 - val_accuracy: 0.4516\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6728 - accuracy: 0.5837 - val_loss: 0.7943 - val_accuracy: 0.4516\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6705 - accuracy: 0.5878 - val_loss: 0.7945 - val_accuracy: 0.4839\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6711 - accuracy: 0.6082 - val_loss: 0.7912 - val_accuracy: 0.4839\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6702 - accuracy: 0.5959 - val_loss: 0.7943 - val_accuracy: 0.4839\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6699 - accuracy: 0.6041 - val_loss: 0.7937 - val_accuracy: 0.4839\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6620 - accuracy: 0.6000 - val_loss: 0.7952 - val_accuracy: 0.4839\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6687 - accuracy: 0.6122 - val_loss: 0.7942 - val_accuracy: 0.4677\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6705 - accuracy: 0.6000 - val_loss: 0.7943 - val_accuracy: 0.4677\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6633 - accuracy: 0.5918 - val_loss: 0.7952 - val_accuracy: 0.4677\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6649 - accuracy: 0.6000 - val_loss: 0.7967 - val_accuracy: 0.4677\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6690 - accuracy: 0.5755 - val_loss: 0.7973 - val_accuracy: 0.4516\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6684 - accuracy: 0.5959 - val_loss: 0.7949 - val_accuracy: 0.4516\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6651 - accuracy: 0.5959 - val_loss: 0.7954 - val_accuracy: 0.4516\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6626 - accuracy: 0.5796 - val_loss: 0.7940 - val_accuracy: 0.4516\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6678 - accuracy: 0.5918 - val_loss: 0.7961 - val_accuracy: 0.4516\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6685 - accuracy: 0.6122 - val_loss: 0.7944 - val_accuracy: 0.4516\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6716 - accuracy: 0.5959 - val_loss: 0.7967 - val_accuracy: 0.4516\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6661 - accuracy: 0.6000 - val_loss: 0.7956 - val_accuracy: 0.4516\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6657 - accuracy: 0.5673 - val_loss: 0.7983 - val_accuracy: 0.4516\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6672 - accuracy: 0.5918 - val_loss: 0.7975 - val_accuracy: 0.4516\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6663 - accuracy: 0.6122 - val_loss: 0.7976 - val_accuracy: 0.4516\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6701 - accuracy: 0.5878 - val_loss: 0.7976 - val_accuracy: 0.4516\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6719 - accuracy: 0.6041 - val_loss: 0.7945 - val_accuracy: 0.4194\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6646 - accuracy: 0.6041 - val_loss: 0.7924 - val_accuracy: 0.4194\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6648 - accuracy: 0.6204 - val_loss: 0.7911 - val_accuracy: 0.4194\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6675 - accuracy: 0.5837 - val_loss: 0.7922 - val_accuracy: 0.4194\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6642 - accuracy: 0.6041 - val_loss: 0.7989 - val_accuracy: 0.4355\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6666 - accuracy: 0.5959 - val_loss: 0.8020 - val_accuracy: 0.4355\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6659 - accuracy: 0.5878 - val_loss: 0.8034 - val_accuracy: 0.4355\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6716 - accuracy: 0.5918 - val_loss: 0.8044 - val_accuracy: 0.4355\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6677 - accuracy: 0.6122 - val_loss: 0.7995 - val_accuracy: 0.4194\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6695 - accuracy: 0.6082 - val_loss: 0.7999 - val_accuracy: 0.4194\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6677 - accuracy: 0.5837 - val_loss: 0.8017 - val_accuracy: 0.4194\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6683 - accuracy: 0.6041 - val_loss: 0.7988 - val_accuracy: 0.4194\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6693 - accuracy: 0.6245 - val_loss: 0.7996 - val_accuracy: 0.4194\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6647 - accuracy: 0.5959 - val_loss: 0.8034 - val_accuracy: 0.4194\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6599 - accuracy: 0.6041 - val_loss: 0.7989 - val_accuracy: 0.4194\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6662 - accuracy: 0.5755 - val_loss: 0.8017 - val_accuracy: 0.4194\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6657 - accuracy: 0.6082 - val_loss: 0.8009 - val_accuracy: 0.4194\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6674 - accuracy: 0.5959 - val_loss: 0.8045 - val_accuracy: 0.4194\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6641 - accuracy: 0.6000 - val_loss: 0.8047 - val_accuracy: 0.4194\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6673 - accuracy: 0.6122 - val_loss: 0.8051 - val_accuracy: 0.4194\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6641 - accuracy: 0.6204 - val_loss: 0.8018 - val_accuracy: 0.4194\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6631 - accuracy: 0.6122 - val_loss: 0.8028 - val_accuracy: 0.4194\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6697 - accuracy: 0.6082 - val_loss: 0.8029 - val_accuracy: 0.4194\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6716 - accuracy: 0.5837 - val_loss: 0.8036 - val_accuracy: 0.4194\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6702 - accuracy: 0.6041 - val_loss: 0.7992 - val_accuracy: 0.4194\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7992 - accuracy: 0.4194\n",
            "Loss on test data: 0.7992\n",
            "Accuracy on test data: 0.4194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aapl[\"MA\"] = ta.ma(\"ema\",aapl.Close,length=10)\n",
        "aapl = aapl.dropna()"
      ],
      "metadata": {
        "id": "a6vTlrTZOSRa"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split data into training and testing sets\n",
        "X = aapl[[\"Positive\", \"Negative\",\"MA\"]]\n",
        "Y = aapl[\"ROC\"]\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.4, shuffle=False)\n",
        "\n",
        "# Build the neural network\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(3,)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Sigmoid activation for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, epochs=100, validation_data=(X_test, Y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(f\"Accuracy on test data: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDxHyETrQNCs",
        "outputId": "339189c4-c201-4b87-b215-9f5c7d01bbc5"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 1s 44ms/step - loss: 0.7055 - accuracy: 0.4551 - val_loss: 0.6940 - val_accuracy: 0.5083\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6847 - accuracy: 0.5618 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.5562 - val_loss: 0.6941 - val_accuracy: 0.5083\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6793 - accuracy: 0.5955 - val_loss: 0.6953 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6769 - accuracy: 0.6067 - val_loss: 0.6980 - val_accuracy: 0.4917\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6697 - accuracy: 0.6348 - val_loss: 0.7005 - val_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6651 - accuracy: 0.6292 - val_loss: 0.7032 - val_accuracy: 0.4917\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6558 - accuracy: 0.6404 - val_loss: 0.7061 - val_accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6615 - accuracy: 0.6180 - val_loss: 0.7091 - val_accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6522 - accuracy: 0.6404 - val_loss: 0.7106 - val_accuracy: 0.5083\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6568 - accuracy: 0.6348 - val_loss: 0.7127 - val_accuracy: 0.5083\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6571 - accuracy: 0.6404 - val_loss: 0.7152 - val_accuracy: 0.4833\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6471 - accuracy: 0.6461 - val_loss: 0.7174 - val_accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6544 - accuracy: 0.6517 - val_loss: 0.7202 - val_accuracy: 0.4917\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6524 - accuracy: 0.6404 - val_loss: 0.7220 - val_accuracy: 0.4833\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6485 - accuracy: 0.6573 - val_loss: 0.7239 - val_accuracy: 0.4750\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6523 - accuracy: 0.6292 - val_loss: 0.7254 - val_accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6525 - accuracy: 0.6404 - val_loss: 0.7262 - val_accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6451 - accuracy: 0.6461 - val_loss: 0.7271 - val_accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6499 - accuracy: 0.6404 - val_loss: 0.7295 - val_accuracy: 0.4917\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6550 - accuracy: 0.6348 - val_loss: 0.7316 - val_accuracy: 0.4917\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6524 - accuracy: 0.6404 - val_loss: 0.7327 - val_accuracy: 0.4917\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6470 - accuracy: 0.6124 - val_loss: 0.7329 - val_accuracy: 0.4917\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6447 - accuracy: 0.6517 - val_loss: 0.7347 - val_accuracy: 0.4917\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6498 - accuracy: 0.6404 - val_loss: 0.7360 - val_accuracy: 0.4917\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6422 - accuracy: 0.6573 - val_loss: 0.7371 - val_accuracy: 0.4917\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6465 - accuracy: 0.6348 - val_loss: 0.7390 - val_accuracy: 0.4917\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6447 - accuracy: 0.6348 - val_loss: 0.7392 - val_accuracy: 0.4917\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6452 - accuracy: 0.6461 - val_loss: 0.7400 - val_accuracy: 0.4917\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6452 - accuracy: 0.6404 - val_loss: 0.7408 - val_accuracy: 0.4917\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6487 - accuracy: 0.6180 - val_loss: 0.7417 - val_accuracy: 0.4917\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6460 - accuracy: 0.6348 - val_loss: 0.7424 - val_accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6471 - accuracy: 0.6348 - val_loss: 0.7450 - val_accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6401 - accuracy: 0.6517 - val_loss: 0.7458 - val_accuracy: 0.5000\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6418 - accuracy: 0.6292 - val_loss: 0.7465 - val_accuracy: 0.5083\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6455 - accuracy: 0.6348 - val_loss: 0.7473 - val_accuracy: 0.5000\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6418 - accuracy: 0.6292 - val_loss: 0.7465 - val_accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6391 - accuracy: 0.6292 - val_loss: 0.7481 - val_accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6427 - accuracy: 0.6292 - val_loss: 0.7493 - val_accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6459 - accuracy: 0.6236 - val_loss: 0.7489 - val_accuracy: 0.4917\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6318 - accuracy: 0.6404 - val_loss: 0.7490 - val_accuracy: 0.4917\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6433 - accuracy: 0.6517 - val_loss: 0.7494 - val_accuracy: 0.4917\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6362 - accuracy: 0.6404 - val_loss: 0.7500 - val_accuracy: 0.4917\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6347 - accuracy: 0.6348 - val_loss: 0.7509 - val_accuracy: 0.5000\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6429 - accuracy: 0.6180 - val_loss: 0.7512 - val_accuracy: 0.5083\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6387 - accuracy: 0.6461 - val_loss: 0.7512 - val_accuracy: 0.5000\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6389 - accuracy: 0.6348 - val_loss: 0.7511 - val_accuracy: 0.5000\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6347 - accuracy: 0.6517 - val_loss: 0.7518 - val_accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6407 - accuracy: 0.6236 - val_loss: 0.7522 - val_accuracy: 0.4917\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6365 - accuracy: 0.6348 - val_loss: 0.7526 - val_accuracy: 0.4917\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6391 - accuracy: 0.6292 - val_loss: 0.7532 - val_accuracy: 0.4917\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6337 - accuracy: 0.6348 - val_loss: 0.7531 - val_accuracy: 0.4917\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6411 - accuracy: 0.6404 - val_loss: 0.7529 - val_accuracy: 0.5083\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6346 - accuracy: 0.6404 - val_loss: 0.7549 - val_accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6441 - accuracy: 0.6292 - val_loss: 0.7560 - val_accuracy: 0.5250\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6325 - accuracy: 0.6517 - val_loss: 0.7567 - val_accuracy: 0.5250\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6380 - accuracy: 0.6236 - val_loss: 0.7575 - val_accuracy: 0.5250\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6409 - accuracy: 0.6348 - val_loss: 0.7574 - val_accuracy: 0.5250\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6363 - accuracy: 0.6292 - val_loss: 0.7580 - val_accuracy: 0.5167\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6333 - accuracy: 0.6180 - val_loss: 0.7584 - val_accuracy: 0.5167\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6373 - accuracy: 0.6348 - val_loss: 0.7608 - val_accuracy: 0.5250\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6366 - accuracy: 0.6292 - val_loss: 0.7615 - val_accuracy: 0.5250\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6359 - accuracy: 0.6348 - val_loss: 0.7608 - val_accuracy: 0.5083\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6297 - accuracy: 0.6348 - val_loss: 0.7611 - val_accuracy: 0.5083\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6246 - accuracy: 0.6461 - val_loss: 0.7607 - val_accuracy: 0.5083\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6378 - accuracy: 0.6236 - val_loss: 0.7617 - val_accuracy: 0.5167\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6384 - accuracy: 0.6348 - val_loss: 0.7617 - val_accuracy: 0.5167\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6381 - accuracy: 0.6292 - val_loss: 0.7619 - val_accuracy: 0.5000\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6380 - accuracy: 0.6404 - val_loss: 0.7622 - val_accuracy: 0.5167\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.6280 - accuracy: 0.6292 - val_loss: 0.7641 - val_accuracy: 0.5083\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6332 - accuracy: 0.6348 - val_loss: 0.7645 - val_accuracy: 0.5000\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6368 - accuracy: 0.6517 - val_loss: 0.7649 - val_accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6317 - accuracy: 0.6236 - val_loss: 0.7664 - val_accuracy: 0.5000\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6392 - accuracy: 0.6348 - val_loss: 0.7673 - val_accuracy: 0.4917\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6357 - accuracy: 0.6180 - val_loss: 0.7670 - val_accuracy: 0.5000\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6352 - accuracy: 0.6404 - val_loss: 0.7671 - val_accuracy: 0.5000\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6449 - accuracy: 0.6461 - val_loss: 0.7666 - val_accuracy: 0.5000\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6338 - accuracy: 0.6348 - val_loss: 0.7674 - val_accuracy: 0.5083\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6212 - accuracy: 0.6404 - val_loss: 0.7685 - val_accuracy: 0.5083\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6208 - accuracy: 0.6461 - val_loss: 0.7697 - val_accuracy: 0.5167\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6361 - accuracy: 0.6517 - val_loss: 0.7705 - val_accuracy: 0.5000\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6307 - accuracy: 0.6348 - val_loss: 0.7711 - val_accuracy: 0.5083\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.6242 - accuracy: 0.6461 - val_loss: 0.7718 - val_accuracy: 0.5167\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6231 - accuracy: 0.6629 - val_loss: 0.7729 - val_accuracy: 0.5250\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6284 - accuracy: 0.6404 - val_loss: 0.7740 - val_accuracy: 0.5250\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6402 - accuracy: 0.6348 - val_loss: 0.7718 - val_accuracy: 0.5000\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6299 - accuracy: 0.6404 - val_loss: 0.7721 - val_accuracy: 0.5000\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6304 - accuracy: 0.6517 - val_loss: 0.7719 - val_accuracy: 0.5000\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6372 - accuracy: 0.6124 - val_loss: 0.7724 - val_accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6251 - accuracy: 0.6236 - val_loss: 0.7729 - val_accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6230 - accuracy: 0.6461 - val_loss: 0.7745 - val_accuracy: 0.5083\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6185 - accuracy: 0.6629 - val_loss: 0.7757 - val_accuracy: 0.5083\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6254 - accuracy: 0.6629 - val_loss: 0.7764 - val_accuracy: 0.5167\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.6273 - accuracy: 0.6404 - val_loss: 0.7778 - val_accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.6248 - accuracy: 0.6685 - val_loss: 0.7769 - val_accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6315 - accuracy: 0.6404 - val_loss: 0.7783 - val_accuracy: 0.4917\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.6222 - accuracy: 0.6461 - val_loss: 0.7783 - val_accuracy: 0.4833\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.6268 - accuracy: 0.6573 - val_loss: 0.7789 - val_accuracy: 0.5000\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.6199 - accuracy: 0.6461 - val_loss: 0.7795 - val_accuracy: 0.5000\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6303 - accuracy: 0.6348 - val_loss: 0.7807 - val_accuracy: 0.4833\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7807 - accuracy: 0.4833\n",
            "Accuracy on test data: 0.4833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kZHo7p1GReJH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
